# revenge_downloader_unicode_fixed.py - ìœ ë‹ˆì½”ë“œ ì™„ì „ ì •ë³µ ë²„ì „!
import sys
import io

# ğŸ”¥ ìœ ë‹ˆì½”ë“œ ë§ˆìŠ¤í„° ì„¤ì • (ë§¨ ìœ„ì— ë°°ì¹˜!)
sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')

import pandas as pd
import asyncio
import aiohttp
from aiohttp import TCPConnector, ClientTimeout
import zipfile
import io
import os
from tqdm import tqdm
from datetime import datetime, timedelta
import time
import random
import logging
from typing import List, Set
import json

# ê¸°ì¡´ ì„¤ì •ë“¤...
SYMBOL = 'BTCUSDT'
START_DATE_STR = '2021-01-01'
END_DATE_STR = '2025-06-01'
DOLLAR_BAR_THRESHOLD = 5_000_000
OUTPUT_DIR = 'data'
TEMP_DIR = 'daily_cache'

CONCURRENT_DOWNLOADS = 15
MAX_RETRIES = 8
BASE_RETRY_DELAY = 3
MAX_RETRY_DELAY = 120
BATCH_SIZE = 100
PROGRESS_FILE = 'smart_download_progress.json'

# ğŸ¯ ìœ ë‹ˆì½”ë“œ ì•ˆì „ ë¡œê¹… ì„¤ì •
class UnicodeFormatter(logging.Formatter):
    """ìœ ë‹ˆì½”ë“œ ì•ˆì „ ë¡œê±° í¬ë§¤í„°"""
    def format(self, record):
        try:
            # ê¸°ë³¸ í¬ë§¤íŒ…
            msg = super().format(record)
            # UTF-8ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì¸ì½”ë”©
            return msg.encode('utf-8', errors='replace').decode('utf-8')
        except Exception:
            # ìµœì•…ì˜ ê²½ìš° ì•„ìŠ¤í‚¤ë§Œ ë‚¨ê¸°ê¸°
            return str(record.getMessage()).encode('ascii', errors='replace').decode('ascii')

# ë¡œê¹… ì„¤ì • (ìœ ë‹ˆì½”ë“œ ì™„ì „ ëŒ€ì‘)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('download.log', encoding='utf-8'),  # íŒŒì¼ë„ UTF-8!
        logging.StreamHandler(sys.stdout)  # ì´ë¯¸ UTF-8ë¡œ ì„¤ì •ëœ stdout ì‚¬ìš©
    ]
)

# ëª¨ë“  í•¸ë“¤ëŸ¬ì— ìœ ë‹ˆì½”ë“œ í¬ë§¤í„° ì ìš©
for handler in logging.getLogger().handlers:
    handler.setFormatter(UnicodeFormatter())

logger = logging.getLogger(__name__)

def exponential_backoff_delay(attempt: int, base_delay: float = BASE_RETRY_DELAY) -> float:
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ê³„ì‚° (ì§€í„° í¬í•¨)"""
    delay = min(base_delay * (2 ** attempt), MAX_RETRY_DELAY)
    jitter = random.uniform(0.1, 0.3) * delay
    return delay + jitter

def save_smart_progress(completed_dates: Set[str], failed_dates: Set[str]):
    """ì§€ëŠ¥í˜• ì§„í–‰ë¥  ì €ì¥ (UTF-8 ê°•ì œ)"""
    progress = {
        'completed_dates': list(completed_dates),
        'failed_dates': list(failed_dates),
        'timestamp': datetime.now().isoformat(),
        'total_completed': len(completed_dates),
        'total_failed': len(failed_dates)
    }
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:  # UTF-8 ëª…ì‹œ!
        json.dump(progress, f, indent=2, ensure_ascii=False)

def load_smart_progress():
    """ì§€ëŠ¥í˜• ì§„í–‰ë¥  ë¡œë“œ"""
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:  # UTF-8 ëª…ì‹œ!
                data = json.load(f)
                return set(data.get('completed_dates', [])), set(data.get('failed_dates', []))
        except Exception as e:
            logger.warning(f"ì§„í–‰ë¥  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ì²˜ìŒë¶€í„° ì‹œì‘")
    return set(), set()

# ğŸ¨ ì´ëª¨ì§€ ì•ˆì „ ë¡œê·¸ í•¨ìˆ˜ë“¤
def safe_log_success(date_str: str, count: int, attempt: int):
    """ì•ˆì „í•œ ì„±ê³µ ë¡œê·¸"""
    try:
        logger.info(f"âœ… {date_str}: {count:,}ê±´ ì €ì¥ ì™„ë£Œ (ì‹œë„ {attempt})")
    except UnicodeEncodeError:
        logger.info(f"[SUCCESS] {date_str}: {count:,}ê±´ ì €ì¥ ì™„ë£Œ (ì‹œë„ {attempt})")

def safe_log_error(date_str: str, message: str):
    """ì•ˆì „í•œ ì—ëŸ¬ ë¡œê·¸"""
    try:
        logger.error(f"âŒ {date_str}: {message}")
    except UnicodeEncodeError:
        logger.error(f"[ERROR] {date_str}: {message}")

def safe_log_warning(date_str: str, message: str):
    """ì•ˆì „í•œ ê²½ê³  ë¡œê·¸"""
    try:
        logger.warning(f"âš ï¸ {date_str}: {message}")
    except UnicodeEncodeError:
        logger.warning(f"[WARNING] {date_str}: {message}")

async def smart_download_with_backoff_unicode_safe(session, date_str, symbol, temp_dir, completed_dates, failed_dates):
    """ìœ ë‹ˆì½”ë“œ ì•ˆì „ ë²„ì „ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜"""
    cache_file = f"{temp_dir}/{date_str}.parquet"
    
    if date_str in completed_dates or os.path.exists(cache_file):
        return 'already_completed'
    
    if date_str in failed_dates:
        return 'previously_failed'
    
    url = f"https://data.binance.vision/data/futures/um/daily/trades/{symbol}/{symbol}-trades-{date_str}.zip"
    
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            if attempt > 1:
                delay = exponential_backoff_delay(attempt - 1)
                try:
                    logger.info(f"ğŸ”„ {date_str}: {delay:.1f}ì´ˆ ëŒ€ê¸° í›„ {attempt}ë²ˆì§¸ ì‹œë„")
                except UnicodeEncodeError:
                    logger.info(f"[RETRY] {date_str}: {delay:.1f}ì´ˆ ëŒ€ê¸° í›„ {attempt}ë²ˆì§¸ ì‹œë„")
                await asyncio.sleep(delay)
            else:
                await asyncio.sleep(random.uniform(0.1, 1.0))
            
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=60)) as response:
                if response.status == 200:
                    content = await response.read()
                    
                    with zipfile.ZipFile(io.BytesIO(content)) as z:
                        csv_filename = z.namelist()[0]
                        with z.open(csv_filename) as csv_file:
                            df = pd.read_csv(
                                csv_file,
                                header=None,
                                dtype='str',
                                low_memory=False
                            )
                            
                            if len(df.columns) >= 6:
                                df.columns = ['trade_id', 'price', 'qty', 'quote_qty', 'timestamp', 'is_buyer_maker']
                                
                                try:
                                    df['trade_id'] = pd.to_numeric(df['trade_id'], errors='coerce')
                                    df['price'] = pd.to_numeric(df['price'], errors='coerce')
                                    df['qty'] = pd.to_numeric(df['qty'], errors='coerce')
                                    df['quote_qty'] = pd.to_numeric(df['quote_qty'], errors='coerce')
                                    df['timestamp'] = pd.to_numeric(df['timestamp'], errors='coerce')
                                    df['is_buyer_maker'] = df['is_buyer_maker'].map({
                                        'true': True, 'false': False, True: True, False: False
                                    })
                                    
                                    df = df.dropna()
                                    
                                    if len(df) > 0:
                                        df.to_parquet(cache_file, compression='snappy')
                                        completed_dates.add(date_str)
                                        safe_log_success(date_str, len(df), attempt)
                                        return 'success'
                                        
                                except Exception as e:
                                    safe_log_error(date_str, f"ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")
                                    failed_dates.add(date_str)
                                    return 'data_error'
                            else:
                                safe_log_error(date_str, f"ì»¬ëŸ¼ ë¶€ì¡± ({len(df.columns)}ê°œ)")
                                failed_dates.add(date_str)
                                return 'format_error'
                                
                elif response.status == 404:
                    safe_log_warning(date_str, "ë°ì´í„° ì—†ìŒ (404)")
                    return 'not_found'
                elif response.status == 429:
                    safe_log_warning(date_str, "Rate limit (429) - ë” ì˜¤ë˜ ëŒ€ê¸°")
                    await asyncio.sleep(exponential_backoff_delay(attempt + 2))
                    continue
                elif response.status >= 500:
                    safe_log_warning(date_str, f"ì„œë²„ ì˜¤ë¥˜ ({response.status}) - ì¬ì‹œë„")
                    continue
                else:
                    safe_log_warning(date_str, f"HTTP {response.status}")
                    
        except asyncio.TimeoutError:
            safe_log_warning(date_str, f"íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt})")
        except aiohttp.ClientConnectorError as e:
            safe_log_warning(date_str, f"ì—°ê²° ì˜¤ë¥˜ (ì‹œë„ {attempt}) - {e}")
        except Exception as e:
            safe_log_warning(date_str, f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì‹œë„ {attempt}) - {e}")
    
    safe_log_error(date_str, "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    failed_dates.add(date_str)
    return 'max_retries_exceeded'

async def smart_revenge_download_unicode_master():
    """ìœ ë‹ˆì½”ë“œ ë§ˆìŠ¤í„° ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ"""
    try:
        # ğŸ¨ ì•ˆì „í•œ ì´ëª¨ì§€ ì¶œë ¥
        print("ğŸ§ ğŸ”¥ ì§€ëŠ¥í˜• ë³µìˆ˜ ë‹¤ìš´ë¡œë” ì‹œì‘! (ìœ ë‹ˆì½”ë“œ ë§ˆìŠ¤í„° ë²„ì „) ğŸ”¥ğŸ§ ")
    except UnicodeEncodeError:
        print("[UNICODE MASTER] ì§€ëŠ¥í˜• ë³µìˆ˜ ë‹¤ìš´ë¡œë” ì‹œì‘!")
    
    os.makedirs(TEMP_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    start_date = datetime.strptime(START_DATE_STR, '%Y-%m-%d').date()
    end_date = datetime.strptime(END_DATE_STR, '%Y-%m-%d').date()
    dates = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') 
             for i in range((end_date - start_date).days)]
    
    # ì§€ëŠ¥í˜• ì§„í–‰ë¥  ë¡œë“œ
    completed_dates, failed_dates = load_smart_progress()
    remaining_dates = [d for d in dates if d not in completed_dates and d not in failed_dates]
    
    # ì•ˆì „í•œ ì¶œë ¥
    print(f"ğŸ“Š ì „ì²´: {len(dates)}ì¼")
    print(f"âœ… ì™„ë£Œ: {len(completed_dates)}ì¼")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_dates)}ì¼")
    print(f"â³ ë‚¨ì€ ì‘ì—…: {len(remaining_dates)}ì¼")
    print(f"ğŸ¯ ë™ì‹œ ì—°ê²°: {CONCURRENT_DOWNLOADS}ê°œ")
    
    if len(remaining_dates) == 0:
        if len(failed_dates) > 0:
            retry_failed = input(f"\nâ“ {len(failed_dates)}ê°œ ì‹¤íŒ¨ íŒŒì¼ ì¬ì‹œë„? (y/n): ")
            if retry_failed.lower() == 'y':
                remaining_dates = list(failed_dates)
                failed_dates.clear()
            else:
                print("ğŸ‰ ì‘ì—… ì™„ë£Œ!")
                return
        else:
            print("ğŸ‰ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for batch_start in range(0, len(remaining_dates), BATCH_SIZE):
        batch_dates = remaining_dates[batch_start:batch_start + BATCH_SIZE]
        batch_num = batch_start // BATCH_SIZE + 1
        total_batches = (len(remaining_dates) + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\nğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_dates)}ê°œ)")
        
        semaphore = asyncio.Semaphore(CONCURRENT_DOWNLOADS)
        connector = TCPConnector(
            limit=CONCURRENT_DOWNLOADS * 2,
            limit_per_host=CONCURRENT_DOWNLOADS,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30
        )
        timeout = ClientTimeout(total=60, connect=30)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            async def download_with_semaphore(date_str):
                async with semaphore:
                    return await smart_download_with_backoff_unicode_safe(
                        session, date_str, SYMBOL, TEMP_DIR, completed_dates, failed_dates
                    )
            
            tasks = [download_with_semaphore(date) for date in batch_dates]
            
            start_time = time.time()
            results = []
            
            # tqdmë„ ìœ ë‹ˆì½”ë“œ ì•ˆì „í•˜ê²Œ
            for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), 
                         desc=f"ğŸ§  ë°°ì¹˜ {batch_num} ìœ ë‹ˆì½”ë“œ ë§ˆìŠ¤í„° ë‹¤ìš´ë¡œë“œ", 
                         ascii=True):  # ASCII ëª¨ë“œë¡œ ì•ˆì „í•˜ê²Œ!
                result = await f
                results.append(result)
            
            # ë°°ì¹˜ ì™„ë£Œ í›„ ì§„í–‰ë¥  ì €ì¥
            save_smart_progress(completed_dates, failed_dates)
            
            elapsed = time.time() - start_time
            success_count = results.count('success')
            already_completed = results.count('already_completed')
            
            print(f"âš¡ ë°°ì¹˜ {batch_num} ì™„ë£Œ!")
            print(f"ğŸ¯ ì„±ê³µ: {success_count}ê°œ")
            print(f"âœ… ì´ë¯¸ ì™„ë£Œ: {already_completed}ê°œ") 
            print(f"âŒ ì‹¤íŒ¨: {len([r for r in results if r not in ['success', 'already_completed']])}ê°œ")
            print(f"â±ï¸ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            
            if batch_num < total_batches:
                rest_time = random.uniform(5, 15)
                print(f"ğŸ˜´ ë°°ì¹˜ ê°„ íœ´ì‹: {rest_time:.1f}ì´ˆ")
                await asyncio.sleep(rest_time)
    
    # ìµœì¢… í†µê³„
    final_completed, final_failed = load_smart_progress()
    total_success_rate = (len(final_completed) / len(dates)) * 100
    
    print(f"\nğŸ‰ ìœ ë‹ˆì½”ë“œ ë§ˆìŠ¤í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… ì„±ê³µë¥ : {total_success_rate:.1f}%")
    print(f"âœ… ì„±ê³µ: {len(final_completed)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(final_failed)}ê°œ")
    
    return final_completed, final_failed

if __name__ == '__main__':
    asyncio.run(smart_revenge_download_unicode_master())
