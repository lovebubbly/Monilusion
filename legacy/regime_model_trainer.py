import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_sample_weight
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import os

def train_regime_classifier(df: pd.DataFrame, test_size: float = 0.2):
    """
    ë ˆì´ë¸”ë§ëœ ë°ì´í„°ë¡œ XGBoost ì‹œì¥ êµ­ë©´ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.
    í•™ìŠµëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë„êµ¬ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): 'regime' ì»¬ëŸ¼ê³¼ í”¼ì²˜ë“¤ì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„.
        test_size (float): í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ë¹„ìœ¨.
    """
    print("ğŸš€ XGBoost ì‹œì¥ êµ­ë©´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # --- 1. ë°ì´í„° ì¤€ë¹„: í”¼ì²˜(X)ì™€ íƒ€ê²Ÿ(y) ë¶„ë¦¬ ---
    # íƒ€ê²Ÿ ë³€ìˆ˜ 'regime'ì„ ì œì™¸í•œ ëª¨ë“  ì»¬ëŸ¼ì„ í”¼ì²˜ë¡œ ì‚¬ìš©
    # timestamp, open, high, low, close ë“±ì€ ëª¨ë¸ í•™ìŠµì— ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    features_to_drop = ['timestamp', 'open', 'high', 'low', 'close', 'regime']
    X = df.drop(columns=features_to_drop, errors='ignore')
    y = df['regime']

    print(f"âœ… ì‚¬ìš©ëœ í”¼ì²˜ ê°œìˆ˜: {len(X.columns)}ê°œ")
    print(f"í”¼ì²˜ ëª©ë¡: {X.columns.tolist()}")

    # --- 2. íƒ€ê²Ÿ ë ˆì´ë¸” ì¸ì½”ë”© ---
    # ë¬¸ìì—´ ë ˆì´ë¸”(e.g., 'Strong_Bull_Trend')ì„ ìˆ«ì(0, 1, 2...)ë¡œ ë³€í™˜
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    print("\n--- ë ˆì´ë¸” ì¸ì½”ë”© ë§µ ---")
    for i, class_name in enumerate(le.classes_):
        print(f"{i}: {class_name}")

    # --- 3. ë°ì´í„° ë¶„í• : í•™ìŠµìš© vs í…ŒìŠ¤íŠ¸ìš© ---
    # ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ, ìˆœì„œë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ shuffle=False ì˜µì…˜ ì‚¬ìš©
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=test_size, shuffle=False
    )
    print(f"\n- í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ / í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

    # --- 4. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ---
    # í”¼ì²˜ë“¤ì˜ ë‹¨ìœ„ë¥¼ í†µì¼ì‹œì¼œ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚´
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("- í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ (StandardScaler)")

    # --- 5. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚° ---
    # ë°ì´í„°ê°€ ì ì€ í´ë˜ìŠ¤ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ í•™ìŠµì„ ìœ ë„
    # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)
    # print("- í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •ì„ ìœ„í•œ ìƒ˜í”Œ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ")
    # XGBoostëŠ” scale_pos_weight íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” ëŒ€ì‹ 
    # DMatrix ìƒì„± ì‹œ `weight` íŒŒë¼ë¯¸í„° ì‚¬ìš©ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ë” ê°„ë‹¨í•œ ì ‘ê·¼ì€ ê° í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•˜ì—¬ `scale_pos_weight`ì— í™œìš©í•˜ëŠ” ê²ƒì´ì§€ë§Œ
    # ë‹¤ì¤‘ í´ë˜ìŠ¤ì—ì„œëŠ” ì§ì ‘ì ì¸ `scale_pos_weight` ì„¤ì •ì´ ë³µì¡í•˜ë¯€ë¡œ,
    # ì—¬ê¸°ì„œëŠ” XGBoostì˜ objective='multi:softmax' ê¸°ë³¸ ê¸°ëŠ¥ì— ì˜ì¡´í•©ë‹ˆë‹¤.
    # ì„±ëŠ¥ì´ ë¶€ì¡±í•  ê²½ìš°, sample_weightë¥¼ DMatrixì— ì „ë‹¬í•˜ëŠ” ë°©ì‹ì„ ì¶”í›„ì— êµ¬í˜„í•©ë‹ˆë‹¤.


    # --- 6. XGBoost ëª¨ë¸ í•™ìŠµ ---
    print("\nğŸ”¥ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    model = xgb.XGBClassifier(
        objective='multi:softmax', # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜
        num_class=len(le.classes_),
        n_estimators=200,          # íŠ¸ë¦¬ì˜ ê°œìˆ˜
        max_depth=5,               # íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´
        learning_rate=0.1,         # í•™ìŠµë¥ 
        use_label_encoder=False,
        eval_metric='mlogloss'
    )
    
    model.fit(X_train_scaled, y_train, verbose=False)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # --- 7. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---
    print("\n--- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°) ---")
    y_pred = model.predict(X_test_scaled)
    
    # Classification Report ì¶œë ¥
    report = classification_report(y_test, y_pred, target_names=le.classes_)
    print(report)

    # Confusion Matrix ì‹œê°í™”
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()
    
    # --- 8. "ì§€ëŠ¥ íŒ¨í‚¤ì§€" ì €ì¥ ---
    # ì‹¤ë§¤ë§¤ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë„êµ¬ë¥¼ ì €ì¥
    output_dir = "intelligence_package"
    os.makedirs(output_dir, exist_ok=True)
    
    model_path = os.path.join(output_dir, "regime_classifier.joblib")
    scaler_path = os.path.join(output_dir, "scaler.joblib")
    encoder_path = os.path.join(output_dir, "label_encoder.joblib")
    
    joblib.dump(model, model_path)
    joblib.dump(scaler, scaler_path)
    joblib.dump(le, encoder_path)
    
    print(f"\nğŸ’¾ 'ì§€ëŠ¥ íŒ¨í‚¤ì§€'ê°€ '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"  - ëª¨ë¸: {model_path}")
    print(f"  - ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
    print(f"  - ì¸ì½”ë”: {encoder_path}")


if __name__ == '__main__':
    try:
        input_parquet_path = "btc_dollar_bars_labeled.parquet"
        labeled_df = pd.read_parquet(input_parquet_path)
        print(f"'{input_parquet_path}' íŒŒì¼ ë¡œë“œ ì„±ê³µ. (ì´ {len(labeled_df)}ê°œ ë°”)")
        
        # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰
        train_regime_classifier(labeled_df)

    except FileNotFoundError:
        print(f"âŒ ì—ëŸ¬: '{input_parquet_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ íŒŒì¼ì„ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
