import pandas as pd
import numpy as np
import numba
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import os
from pathlib import Path
from typing import List, Tuple, Optional

def detect_column_mappings(df: pd.DataFrame) -> dict:
    """
    ğŸ” ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…ì„ ìë™ ê°ì§€í•˜ê³  ë§¤í•‘
    """
    column_mapping = {
        'timestamp': None,
        'price': None,
        'volume': None
    }
    
    columns = df.columns.tolist()
    tqdm.write(f"ğŸ“‹ ë°œê²¬ëœ ì»¬ëŸ¼ë“¤: {columns}")
    
    # timestamp ì»¬ëŸ¼ ì°¾ê¸°
    timestamp_candidates = ['timestamp', 'time', 'datetime', 'date', 'ts']
    for col in columns:
        if any(candidate in col.lower() for candidate in timestamp_candidates):
            column_mapping['timestamp'] = col
            break
    
    # price ì»¬ëŸ¼ ì°¾ê¸°
    price_candidates = ['price', 'close', 'last_price', 'px']
    for col in columns:
        if any(candidate in col.lower() for candidate in price_candidates):
            column_mapping['price'] = col
            break
    
    # volume ì»¬ëŸ¼ ì°¾ê¸°
    volume_candidates = ['volume', 'vol', 'qty', 'quantity', 'size', 'amount', 'base_volume']
    for col in columns:
        if any(candidate in col.lower() for candidate in volume_candidates):
            column_mapping['volume'] = col
            break
    
    # ê²°ê³¼ ì¶œë ¥
    tqdm.write(f"ğŸ¯ ì»¬ëŸ¼ ë§¤í•‘ ê²°ê³¼:")
    for key, value in column_mapping.items():
        tqdm.write(f"   {key}: {value}")
    
    return column_mapping

@numba.njit
def create_dollar_bars_numba_safe(
    timestamps: np.ndarray,
    prices: np.ndarray,
    volumes: np.ndarray,
    dollar_threshold: float,
    start_accumulated: float = 0.0,
    start_idx: int = 0
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, int]:
    """
    ğŸ”¥ Numba ìµœì í™”ëœ ë‹¬ëŸ¬ ë°” ìƒì„± í•¨ìˆ˜ (ì•ˆì „ì„± ê°•í™”)
    """
    n = len(timestamps)
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    bar_timestamps = []
    bar_opens = []
    bar_highs = []
    bar_lows = []
    bar_closes = []
    
    # í˜„ì¬ ë°” ìƒíƒœ
    current_dollar_volume = start_accumulated
    current_open = 0.0
    current_high = 0.0
    current_low = 0.0
    current_close = 0.0
    current_timestamp = 0
    bar_started = False
    
    last_processed_idx = start_idx
    
    for i in range(start_idx, n):
        price = prices[i]
        volume = volumes[i]
        timestamp = timestamps[i]
        
        # ìœ íš¨ì„± ê²€ì‚¬
        if np.isnan(price) or np.isnan(volume) or price <= 0 or volume < 0:
            continue
        
        dollar_amount = price * volume
        
        # ì²« ë²ˆì§¸ í‹±ì´ê±°ë‚˜ ìƒˆ ë°” ì‹œì‘
        if not bar_started:
            current_open = price
            current_high = price
            current_low = price
            current_timestamp = timestamp
            bar_started = True
        else:
            # ê³ ê°€/ì €ê°€ ì—…ë°ì´íŠ¸
            if price > current_high:
                current_high = price
            if price < current_low:
                current_low = price
        
        current_close = price
        current_dollar_volume += dollar_amount
        last_processed_idx = i
        
        # ì„ê³„ê°’ ë„ë‹¬ ì‹œ ë°” ì™„ì„±
        if current_dollar_volume >= dollar_threshold:
            bar_timestamps.append(current_timestamp)
            bar_opens.append(current_open)
            bar_highs.append(current_high)
            bar_lows.append(current_low)
            bar_closes.append(current_close)
            
            # ë‹¤ìŒ ë°”ë¥¼ ìœ„í•œ ì´ˆê¸°í™”
            current_dollar_volume = 0.0
            bar_started = False
    
    # numpy ë°°ì—´ë¡œ ë³€í™˜
    result_timestamps = np.array(bar_timestamps, dtype=np.int64)
    result_opens = np.array(bar_opens, dtype=np.float64)
    result_highs = np.array(bar_highs, dtype=np.float64)
    result_lows = np.array(bar_lows, dtype=np.float64)
    result_closes = np.array(bar_closes, dtype=np.float64)
    
    return (result_timestamps, result_opens, result_highs, result_lows, 
            result_closes, current_dollar_volume, last_processed_idx)

def load_files_from_chunk_safe(chunk_files: List[str]) -> List[pd.DataFrame]:
    """
    ğŸ”¥ ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ íŒŒì¼ ë¡œë”©
    """
    chunk_dfs = []
    
    def read_file_thread_safe(file_path: str) -> Optional[pd.DataFrame]:
        try:
            df = pd.read_parquet(file_path)
            if df is not None and not df.empty:
                return df
            return None
        except Exception as e:
            tqdm.write(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì—ëŸ¬: {e}")
            return None
    
    with ThreadPoolExecutor(max_workers=min(8, len(chunk_files))) as executor:
        futures = [executor.submit(read_file_thread_safe, f) for f in chunk_files]
        
        for future in tqdm(as_completed(futures), total=len(futures), 
                          desc="ğŸ“ íŒŒì¼ ë¡œë”©", leave=False):
            try:
                result = future.result(timeout=60)
                if result is not None:
                    chunk_dfs.append(result)
            except Exception as e:
                tqdm.write(f"âš ï¸ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}")
    
    return chunk_dfs

def prepare_data_with_column_mapping(combined_df: pd.DataFrame, column_mapping: dict) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸ”§ ì»¬ëŸ¼ ë§¤í•‘ì„ ì‚¬ìš©í•´ì„œ ë°ì´í„° ì¤€ë¹„
    """
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ë§¤í•‘
    timestamp_col = column_mapping.get('timestamp')
    price_col = column_mapping.get('price')
    volume_col = column_mapping.get('volume')
    
    # timestamp ì²˜ë¦¬
    if timestamp_col and timestamp_col in combined_df.columns:
        timestamps = combined_df[timestamp_col].values
    else:
        tqdm.write("âš ï¸ timestamp ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
        timestamps = np.arange(len(combined_df), dtype=np.int64)
    
    # price ì²˜ë¦¬
    if price_col and price_col in combined_df.columns:
        prices = combined_df[price_col].values.astype(np.float64)
    else:
        raise ValueError(f"âŒ price ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {combined_df.columns.tolist()}")
    
    # volume ì²˜ë¦¬
    if volume_col and volume_col in combined_df.columns:
        volumes = combined_df[volume_col].values.astype(np.float64)
        tqdm.write(f"âœ… volume ì»¬ëŸ¼ '{volume_col}' ì‚¬ìš©")
    else:
        # volumeì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©
        tqdm.write("âš ï¸ volume ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ê¸°ë³¸ê°’ 1.0ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
        volumes = np.ones(len(combined_df), dtype=np.float64)
    
    return timestamps, prices, volumes


def process_chunk_with_state_carryover(
    chunk_files: List[str], 
    leftover_df: Optional[pd.DataFrame] = None,
    accumulated_dollar_volume: float = 0.0,
    dollar_threshold:float = 152936804.0,
    column_mapping: Optional[dict] = None
) -> Tuple[pd.DataFrame, pd.DataFrame, float, dict]:
    """
    ğŸ”¥ ìƒíƒœ ìœ ì§€ê°€ ì ìš©ëœ ì²­í¬ ì²˜ë¦¬ í•¨ìˆ˜ (ì»¬ëŸ¼ ë§¤í•‘ ì§€ì›)
    """
    
    # 1ë‹¨ê³„: ì•ˆì „í•œ íŒŒì¼ ë¡œë”©
    chunk_dfs = load_files_from_chunk_safe(chunk_files)
    
    if not chunk_dfs:
        return pd.DataFrame(), leftover_df, accumulated_dollar_volume, column_mapping
    
    # 2ë‹¨ê³„: ë°ì´í„° ë³‘í•©
    chunk_trades_df = pd.concat(chunk_dfs, ignore_index=True)
    
    # 3ë‹¨ê³„: ìƒíƒœ ìœ ì§€ - ì´ì „ ì²­í¬ì˜ ì°Œêº¼ê¸°ì™€ í˜„ì¬ ì²­í¬ í•©ì¹˜ê¸°
    if leftover_df is not None and not leftover_df.empty:
        tqdm.write(f"ğŸ”„ ì´ì „ ì²­í¬ ì°Œêº¼ê¸° {len(leftover_df)}ê°œ ë°ì´í„° ì—°ê²°")
        combined_df = pd.concat([leftover_df, chunk_trades_df], ignore_index=True)
    else:
        combined_df = chunk_trades_df
    
    # 4ë‹¨ê³„: ì»¬ëŸ¼ ë§¤í•‘ (ì²« ë²ˆì§¸ ì²­í¬ì—ì„œë§Œ)
    if column_mapping is None:
        column_mapping = detect_column_mappings(combined_df)
    
    # 5ë‹¨ê³„: ë°ì´í„° ì •ë ¬ ë° ì¤€ë¹„
    timestamp_col = column_mapping.get('timestamp')
    if timestamp_col and timestamp_col in combined_df.columns:
        combined_df = combined_df.sort_values(timestamp_col).reset_index(drop=True)
    
    # 6ë‹¨ê³„: ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜
    timestamps, prices, volumes = prepare_data_with_column_mapping(combined_df, column_mapping)
    
    # 7ë‹¨ê³„: Numba ìµœì í™”ëœ ë‹¬ëŸ¬ ë°” ìƒì„±
    (bar_timestamps, bar_opens, bar_highs, bar_lows, bar_closes, 
     remaining_dollar_volume, last_processed_idx) = create_dollar_bars_numba_safe(
        timestamps, prices, volumes, dollar_threshold, accumulated_dollar_volume
    )
    
    # 8ë‹¨ê³„: ì™„ì„±ëœ ë°” ë°ì´í„°í”„ë ˆì„ ìƒì„±
    new_bars_df = pd.DataFrame({
        'timestamp': bar_timestamps,
        'open': bar_opens,
        'high': bar_highs,
        'low': bar_lows,
        'close': bar_closes
    })
    
    # 9ë‹¨ê³„: ë‹¤ìŒ ì²­í¬ë¥¼ ìœ„í•œ ì°Œêº¼ê¸° ë°ì´í„° ìƒì„±
    if last_processed_idx < len(combined_df) - 1:
        leftover_for_next = combined_df.iloc[last_processed_idx + 1:].copy()
        tqdm.write(f"ğŸ“¦ ë‹¤ìŒ ì²­í¬ë¡œ ë„˜ê¸¸ ì°Œêº¼ê¸°: {len(leftover_for_next)}ê°œ ë°ì´í„°")
    else:
        leftover_for_next = pd.DataFrame()
    
    return new_bars_df, leftover_for_next, remaining_dollar_volume, column_mapping

def process_all_files_with_state_management(
    file_paths: List[str],
    chunk_size: int = 20,
    dollar_threshold: float =152936804.0,
    output_file: str = "dollar_bars_result.parquet"
) -> pd.DataFrame:
    """
    ğŸ”¥ ì „ì²´ íŒŒì¼ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ - ì™„ì „ ì•ˆì „í•œ ë²„ì „
    """
    
    # íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• 
    file_chunks = [file_paths[i:i + chunk_size] for i in range(0, len(file_paths), chunk_size)]
    num_chunks = len(file_chunks)
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥ìš©
    all_bars = []
    
    # ìƒíƒœ ìœ ì§€ ë³€ìˆ˜ë“¤
    leftover_df = None
    accumulated_dollar_volume = 0.0
    column_mapping = None
    
    tqdm.write(f"ğŸš€ ì´ {len(file_paths)}ê°œ íŒŒì¼ì„ {num_chunks}ê°œ ì²­í¬ë¡œ ì²˜ë¦¬ ì‹œì‘!")
    tqdm.write(f"ğŸ’° ë‹¬ëŸ¬ ë°” ì„ê³„ê°’: ${dollar_threshold:,.0f}")
    
    with tqdm(total=num_chunks, desc="ğŸ—ï¸ ì²­í¬ ì²˜ë¦¬ ì§„í–‰ë„", unit="ì²­í¬") as pbar:
        for i, chunk in enumerate(file_chunks):
            pbar.set_postfix_str(f"ì²­í¬ {i+1}/{num_chunks} | íŒŒì¼ {len(chunk)}ê°œ")
            
            try:
                # ì²­í¬ ì²˜ë¦¬ (ìƒíƒœ ìœ ì§€ ì ìš©)
                new_bars_df, leftover_df, accumulated_dollar_volume, column_mapping = process_chunk_with_state_carryover(
                    chunk, leftover_df, accumulated_dollar_volume, dollar_threshold, column_mapping
                )
                
                # ì™„ì„±ëœ ë°”ê°€ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
                if not new_bars_df.empty:
                    all_bars.append(new_bars_df)
                    tqdm.write(f"âœ… ì²­í¬ {i+1}: {len(new_bars_df)}ê°œ ë‹¬ëŸ¬ ë°” ìƒì„± ì™„ë£Œ")
                else:
                    tqdm.write(f"âš ï¸ ì²­í¬ {i+1}: ìƒì„±ëœ ë‹¬ëŸ¬ ë°” ì—†ìŒ")
                    
            except Exception as e:
                tqdm.write(f"âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
            
            pbar.update(1)
    
    # ëª¨ë“  ê²°ê³¼ ë³‘í•©
    if all_bars:
        final_result = pd.concat(all_bars, ignore_index=True)
        final_result = final_result.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ê³¼ ì €ì¥
        final_result.to_parquet(output_file, index=False)
        tqdm.write(f"ğŸ‰ ìµœì¢… ê²°ê³¼: {len(final_result)}ê°œ ë‹¬ëŸ¬ ë°” ìƒì„± ì™„ë£Œ!")
        tqdm.write(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_file}")
        
        return final_result
    else:
        tqdm.write("âš ï¸ ìƒì„±ëœ ë‹¬ëŸ¬ ë°”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

# ğŸ”¥ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    data_folder = Path("C:\Monilusion\daily_cache")
    all_files = [str(f) for f in data_folder.glob("*.parquet")]
    
    # íŒŒë¼ë¯¸í„° ì„¤ì •
    CHUNK_SIZE = 20
    DOLLAR_THRESHOLD = 152936804.0
    
    print(f"ğŸ¯ ë°œê²¬ëœ íŒŒì¼ ê°œìˆ˜: {len(all_files)}ê°œ")
    
    # ì²˜ë¦¬ ì‹¤í–‰
    result_df = process_all_files_with_state_management(
        all_files, 
        chunk_size=CHUNK_SIZE,
        dollar_threshold=DOLLAR_THRESHOLD,
        output_file="btc_dollar_bars_optimized.parquet"
    )
    
    if not result_df.empty:
        print(f"\nğŸ† ìµœì¢… ì„±Hê³¼:")
        print(f"   ğŸ“ˆ ìƒì„±ëœ ë‹¬ëŸ¬ ë°”: {len(result_df):,}ê°œ")
        print(f"   â° ì‹œê°„ ë²”ìœ„: {pd.to_datetime(result_df['timestamp'].min(), unit='ms')} ~ {pd.to_datetime(result_df['timestamp'].max(), unit='ms')}")
        print(f"   ğŸ’° ê°€ê²© ë²”ìœ„: ${result_df['low'].min():.2f} ~ ${result_df['high'].max():.2f}")
