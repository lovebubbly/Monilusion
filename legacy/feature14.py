# feature_engineer_14features_future.py - 14ê°œ í”¼ì²˜ ë¯¸ë˜ ì˜ˆì¸¡ ë²„ì „

import pandas as pd
import pandas_ta as ta
import numpy as np
from sklearn.preprocessing import StandardScaler
import os
from tqdm import tqdm
import pickle
import gc

# --- ì„¤ì • ---
INPUT_PARQUET_PATH = 'data/dollar_bars_BTCUSDT_2023-01-01_2024-01-01.parquet'
OUTPUT_DIR = 'C:/processed_data_regime_14features'
SEQUENCE_LENGTH = 128
PREDICTION_HORIZON = 1  # ê²€ìƒ‰ ê²°ê³¼ì™€ ë™ì¼
TEST_SET_RATIO = 0.15
VALIDATION_SET_RATIO = 0.15
DTYPE = 'float32'

def load_and_clean_data(path):
    """ë°ì´í„° ë¡œë“œ ë° ì •ë¦¬"""
    print(f"ğŸ“‚ '{path}'ì—ì„œ ë‹¬ëŸ¬ ë°” ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    try:
        df = pd.read_parquet(path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df):,}ê°œ ë°”")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    df = df.sort_values('open_time').set_index('open_time')
    
    duplicate_count = df.index.duplicated().sum()
    if duplicate_count > 0:
        print(f"ğŸ”§ ì¤‘ë³µ ì¸ë±ìŠ¤ {duplicate_count}ê°œ ë°œê²¬, ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        agg_rules = {
            'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last',
            'volume': 'sum', 'value': 'sum', 'buy_value': 'sum', 'sell_value': 'sum'
        }
        if 'close_time' in df.columns: 
            agg_rules['close_time'] = 'last'
        df = df.groupby(df.index).agg(agg_rules)
        print(f"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(df):,}ê°œ ë°”")
    
    if 'close_time' not in df.columns: 
        df['close_time'] = df.index
    print("âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
    return df

def add_14_features(df):
    """ì •í™•íˆ 14ê°œ í”¼ì²˜ ìƒì„±"""
    print("ğŸ”§ 14ê°œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘...")
    
    # ë°” ì§€ì†ì‹œê°„
    if 'close_time' in df.columns:
        df['close_time'] = pd.to_datetime(df['close_time'])
        df['bar_duration_seconds'] = (df['close_time'] - df.index).dt.total_seconds().clip(lower=0)
    else:
        df['bar_duration_seconds'] = 300

    # OFI ê´€ë ¨ (5ê°œ)
    df['ofi'] = (df['buy_value'] - df['sell_value']) / (df['buy_value'] + df['sell_value'] + 1e-10)
    df['ofi_ema_10'] = ta.ema(df['ofi'], length=10)
    df['ofi_ema_30'] = ta.ema(df['ofi'], length=30)
    df['ofi_volatility'] = df['ofi'].rolling(20).std()

    print("ğŸ“Š ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘...")
    # ê¸°ìˆ ì  ì§€í‘œ (4ê°œ)
    df.ta.ema(length=10, append=True, col_names=('EMA_10',))
    df.ta.ema(length=30, append=True, col_names=('EMA_30',))
    df.ta.rsi(length=14, append=True, col_names=('RSI_14',))
    df.ta.atr(length=14, append=True, col_names=('ATR_14',))

    # ê°€ê²© ê´€ë ¨ (2ê°œ)
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    df['price_change_pct'] = (df['close'] - df['open']) / df['open']

    # ë³¼ë¥¨ ê´€ë ¨ (2ê°œ)
    df['volume_ema_10'] = ta.ema(df['volume'], length=10)
    df['volume_ratio'] = df['volume'] / (df['volume_ema_10'] + 1e-10)

    # ê°€ê²© ëª¨ë©˜í…€ (1ê°œ)
    df['price_momentum'] = (df['close'] - df['close'].shift(20)) / df['close'].shift(20)

    # ì •í™•íˆ 14ê°œ í”¼ì²˜ ì„ íƒ
    feature_cols = [
        'bar_duration_seconds',  # 1
        'ofi',                   # 2  
        'ofi_ema_10',           # 3
        'ofi_ema_30',           # 4
        'ofi_volatility',       # 5
        'EMA_10',               # 6
        'EMA_30',               # 7
        'RSI_14',               # 8
        'ATR_14',               # 9
        'log_return',           # 10
        'price_change_pct',     # 11
        'volume_ema_10',        # 12
        'volume_ratio',         # 13
        'price_momentum'        # 14
    ]

    # ë°ì´í„° íƒ€ì… ìµœì í™”
    for col in feature_cols:
        if col in df.columns and df[col].dtype == 'float64':
            df[col] = df[col].astype(DTYPE)

    initial_length = len(df)
    df.dropna(inplace=True)
    final_length = len(df)
    
    print(f"âœ… 14ê°œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ!")
    print(f"ğŸ“‰ NaN ì œê±°: {initial_length - final_length:,}ê°œ í–‰ ì œê±°")
    
    return df[feature_cols + ['close', 'buy_value', 'sell_value']]  # ë¼ë²¨ë§ìš© ì»¬ëŸ¼ë“¤ í¬í•¨

def create_balanced_regime_labels(df):
    """ê· í˜•ì¡íŒ 3-í´ë˜ìŠ¤ êµ­ë©´ ë¼ë²¨ ìƒì„±"""
    print("ğŸ¯ ê· í˜•ì¡íŒ ì‹œì¥ êµ­ë©´ ë¼ë²¨ë§...")
    
    # ë™ì  ì„ê³„ê°’ ì„¤ì •
    ofi_mean, ofi_std = df['ofi_ema_10'].mean(), df['ofi_ema_10'].std()
    price_mean, price_std = df['price_momentum'].mean(), df['price_momentum'].std()
    
    ofi_upper, ofi_lower = ofi_mean + 0.5 * ofi_std, ofi_mean - 0.5 * ofi_std
    price_upper, price_lower = price_mean + 0.3 * price_std, price_mean - 0.3 * price_std
    
    print(f"ğŸ“Š ì„ê³„ê°’ - OFI: {ofi_lower:.4f}~{ofi_upper:.4f}, ê°€ê²©: {price_lower:.4f}~{price_upper:.4f}")
    
    conditions = [
        (df['ofi_ema_10'] > ofi_upper) | (df['price_momentum'] > price_upper),  # ìƒìŠ¹
        (df['ofi_ema_10'] < ofi_lower) | (df['price_momentum'] < price_lower),  # í•˜ë½
    ]
    choices = [1, 2]
    df['regime'] = np.select(conditions, choices, default=0)  # íš¡ë³´

    # í˜„ì¬ êµ­ë©´ ë¶„í¬
    regime_counts = df['regime'].value_counts().sort_index()
    print("ğŸ“Š í˜„ì¬ ì‹œì¥ êµ­ë©´ ë¶„í¬:")
    regime_names = {0: 'íš¡ë³´', 1: 'ìƒìŠ¹', 2: 'í•˜ë½'}
    for regime, count in regime_counts.items():
        name = regime_names.get(regime, f'êµ­ë©´{regime}')
        print(f"   {regime} ({name}): {count:,}ê°œ ({count/len(df)*100:.1f}%)")
    
    return df

def create_future_prediction_labels(df, horizon):
    """ë¯¸ë˜ ì˜ˆì¸¡ ë¼ë²¨ ìƒì„± (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)"""
    print(f"ğŸ”® ë¯¸ë˜ {horizon}ê°œ ë°” ì´í›„ì˜ êµ­ë©´ì„ ì˜ˆì¸¡ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •...")
    
    # í•µì‹¬: t ì‹œì  í”¼ì²˜ë¡œ t+horizon ì‹œì  êµ­ë©´ ì˜ˆì¸¡
    df['label'] = df['regime'].shift(-horizon)
    
    initial_len = len(df)
    df.dropna(subset=['label'], inplace=True)
    df['label'] = df['label'].astype(int)
    
    print(f"ğŸ”ª ë¯¸ë˜ ë¼ë²¨ ìƒì„± í›„ NaN ì œê±°: {initial_len - len(df)}ê°œ í–‰ ì œê±°")
    
    # ìµœì¢… ì˜ˆì¸¡ ëª©í‘œ ë¶„í¬
    label_dist = df['label'].value_counts(normalize=True).sort_index()
    print("ğŸ“Š ìµœì¢… ì˜ˆì¸¡ ëª©í‘œ(label) ë¶„í¬:")
    regime_names = {0: 'íš¡ë³´', 1: 'ìƒìŠ¹', 2: 'í•˜ë½'}
    for label, percentage in label_dist.items():
        name = regime_names.get(label, f'í´ë˜ìŠ¤{label}')
        print(f"   {label} ({name}): {percentage:.1%}")
    
    return df

def create_sequences_future_prediction(features, labels, seq_length, prediction_horizon=1, dtype='float32'):
    """ê²€ìƒ‰ ê²°ê³¼[1]ì™€ ë™ì¼í•œ ë¯¸ë˜ ì˜ˆì¸¡ ì‹œí€€ìŠ¤ ìƒì„±"""
    print(f"ğŸ”„ {seq_length}ê°œ ê³¼ê±° â†’ {prediction_horizon}ì‹œì  ë¯¸ë˜ ì˜ˆì¸¡ ì‹œí€€ìŠ¤ ìƒì„±...")
    X, y = [], []
    
    # ê²€ìƒ‰ ê²°ê³¼ì™€ ë™ì¼í•œ ë¡œì§
    max_idx = len(features) - seq_length - prediction_horizon + 1
    
    for i in tqdm(range(max_idx), desc="ë¯¸ë˜ ì˜ˆì¸¡ ì‹œí€€ìŠ¤ ìƒì„±"):
        X.append(features[i:(i + seq_length)])
        y.append(labels[i + seq_length + prediction_horizon - 1])
    
    print(f"âœ… ì´ {len(X):,}ê°œ ì‹œí€€ìŠ¤ ìƒì„± (ë¯¸ë˜ {prediction_horizon}ì‹œì  ì˜ˆì¸¡)")
    return np.array(X, dtype=dtype), np.array(y)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Feature Engineering 14ê°œ í”¼ì²˜ ë¯¸ë˜ ì˜ˆì¸¡ ë²„ì „!")
    print("="*80)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # 1. ë°ì´í„° ë¡œë“œ
    df = load_and_clean_data(INPUT_PARQUET_PATH)
    if df is None: return

    # 2. ì •í™•íˆ 14ê°œ í”¼ì²˜ ìƒì„±
    df_featured = add_14_features(df)

    # 3. ê· í˜•ì¡íŒ êµ­ë©´ ë¼ë²¨ë§
    df_regime = create_balanced_regime_labels(df_featured)
    
    # 4. ë¯¸ë˜ ì˜ˆì¸¡ ë¼ë²¨ ìƒì„±
    df_labeled = create_future_prediction_labels(df_regime, PREDICTION_HORIZON)
    
    # 5. í”¼ì²˜ì™€ ë¼ë²¨ ë¶„ë¦¬
    feature_cols = [
        'bar_duration_seconds', 'ofi', 'ofi_ema_10', 'ofi_ema_30', 'ofi_volatility',
        'EMA_10', 'EMA_30', 'RSI_14', 'ATR_14', 'log_return', 
        'price_change_pct', 'volume_ema_10', 'volume_ratio', 'price_momentum'
    ]
    
    features_df = df_labeled[feature_cols]
    labels_series = df_labeled['label']
    
    print(f"\nğŸ“Š ìµœì¢… í™•ì¸:")
    print(f"   í”¼ì²˜ ìˆ˜: {len(feature_cols)}ê°œ (ì •í™•íˆ 14ê°œ!)")
    print(f"   ìƒ˜í”Œ ìˆ˜: {len(features_df):,}ê°œ")

    # 6. ì‹œê°„ ìˆœì„œ ê¸°ë°˜ ë¶„í• 
    n_samples = len(features_df)
    n_test = int(n_samples * TEST_SET_RATIO)
    n_validation = int(n_samples * VALIDATION_SET_RATIO)
    n_train = n_samples - n_test - n_validation

    # 7. ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    train_features_scaled = scaler.fit_transform(features_df.iloc[:n_train]).astype(DTYPE)
    validation_features_scaled = scaler.transform(features_df.iloc[n_train:n_train + n_validation]).astype(DTYPE)
    test_features_scaled = scaler.transform(features_df.iloc[n_train + n_validation:]).astype(DTYPE)
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    with open(os.path.join(OUTPUT_DIR, 'scaler_14features.pkl'), 'wb') as f:
        pickle.dump(scaler, f)

    print("\n--- ğŸ¯ 14ê°œ í”¼ì²˜ ë¯¸ë˜ ì˜ˆì¸¡ ì‹œí€€ìŠ¤ ìƒì„± ---")
    
    # 8. Train Set
    print("\n[1/3] Train Set...")
    X_train, y_train = create_sequences_future_prediction(
        train_features_scaled, labels_series.iloc[:n_train].values, SEQUENCE_LENGTH, PREDICTION_HORIZON
    )
    np.save(os.path.join(OUTPUT_DIR, 'X_train.npy'), X_train)
    np.save(os.path.join(OUTPUT_DIR, 'y_train.npy'), y_train)
    print(f"âœ… Train Set: X={X_train.shape}, y={y_train.shape}")
    del X_train, y_train, train_features_scaled; gc.collect()
    
    # 9. Validation Set  
    print("\n[2/3] Validation Set...")
    X_val, y_val = create_sequences_future_prediction(
        validation_features_scaled, labels_series.iloc[n_train:n_train+n_validation].values, SEQUENCE_LENGTH, PREDICTION_HORIZON
    )
    np.save(os.path.join(OUTPUT_DIR, 'X_val.npy'), X_val)
    np.save(os.path.join(OUTPUT_DIR, 'y_val.npy'), y_val)
    print(f"âœ… Validation Set: X={X_val.shape}, y={y_val.shape}")
    del X_val, y_val, validation_features_scaled; gc.collect()

    # 10. Test Set
    print("\n[3/3] Test Set...")
    X_test, y_test = create_sequences_future_prediction(
        test_features_scaled, labels_series.iloc[n_train+n_validation:].values, SEQUENCE_LENGTH, PREDICTION_HORIZON
    )
    np.save(os.path.join(OUTPUT_DIR, 'X_test.npy'), X_test)
    np.save(os.path.join(OUTPUT_DIR, 'y_test.npy'), y_test)
    print(f"âœ… Test Set: X={X_test.shape}, y={y_test.shape}")
    del X_test, y_test, test_features_scaled; gc.collect()

    print(f"\nğŸ‰ 14ê°œ í”¼ì²˜ ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°ì…‹ ì™„ì„±!")
    print(f"ğŸ’¾ '{OUTPUT_DIR}'ì— ì €ì¥ ì™„ë£Œ")
    print(f"ğŸ”® ì§„ì§œ ë¯¸ë˜ ì˜ˆì¸¡ ëª¨ë¸ì„ ìœ„í•œ ì™„ë²½í•œ êµ¬ì¡°!")

if __name__ == '__main__':
    main()
